{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üîß INSTALLATION DES D√âPENDANCES\n",
      "============================================================\n",
      "‚úÖ boto3 install√©\n",
      "‚úÖ pyarrow install√©\n",
      "‚úÖ pandas install√©\n",
      "‚úÖ pymysql install√©\n",
      "‚úÖ sqlalchemy install√©\n",
      "‚úÖ utils_s3.py trouv√©\n",
      "‚úÖ feature_store.py trouv√©\n",
      "\n",
      "‚úÖ D√©pendances pr√™tes!\n",
      "üí° Si erreurs persistent, red√©marrer le kernel: Kernel > Restart\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# üîß Installation automatique des d√©pendances\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üîß INSTALLATION DES D√âPENDANCES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "packages = [\"boto3>=1.28.0\", \"pyarrow>=12.0.0\", \"pandas>=2.0.0\", \"pymysql>=1.1.0\", \"sqlalchemy>=2.0.0\"]\n",
    "\n",
    "for package in packages:\n",
    "    pkg_name = package.split(\">=\")[0].split(\"==\")[0]\n",
    "    try:\n",
    "        __import__(pkg_name.replace(\"-\", \"_\"))\n",
    "        print(f\"‚úÖ {pkg_name} install√©\")\n",
    "    except ImportError:\n",
    "        print(f\"üì¶ Installation {pkg_name}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package], \n",
    "                             stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "        print(f\"‚úÖ {pkg_name} install√©\")\n",
    "\n",
    "# V√©rifier les fichiers\n",
    "for file in [\"utils_s3.py\", \"feature_store.py\"]:\n",
    "    if Path(file).exists():\n",
    "        print(f\"‚úÖ {file} trouv√©\")\n",
    "    else:\n",
    "        print(f\"‚ùå {file} manquant\")\n",
    "\n",
    "print(\"\\n‚úÖ D√©pendances pr√™tes!\")\n",
    "print(\"üí° Si erreurs persistent, red√©marrer le kernel: Kernel > Restart\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Checklist Pr√©-Pr√©sentation\n",
    "\n",
    "Avant de commencer, v√©rifiez que tout est lanc√© :\n",
    "\n",
    "- ‚úÖ `docker-compose up -d` (tous les services)\n",
    "- ‚úÖ `python generate_prometheus_metrics.py` (en cours d'ex√©cution)\n",
    "- ‚úÖ `kubectl apply -f k8s/` (Kubernetes d√©ploy√©)\n",
    "- ‚úÖ `docker build -t dandelion-grass-classifier:latest .` (image Docker)\n",
    "- ‚úÖ `python train.py` (mod√®le entra√Æn√©)\n",
    "\n",
    "**URLs √† avoir ouvertes** :\n",
    "- MLflow UI : http://localhost:5001\n",
    "- Airflow : http://localhost:8080\n",
    "- Grafana : http://localhost:3000\n",
    "- Prometheus : http://localhost:9090\n",
    "- Minio : http://localhost:9001\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé§ Pr√©sentation - Pipeline MLOps Complet\n",
    "\n",
    "## Classification Binaire : Pissenlit vs Herbe\n",
    "\n",
    "**11/11 objectifs obligatoires ‚úÖ**\n",
    "\n",
    "---\n",
    "\n",
    "## üõ†Ô∏è Stack Technique\n",
    "\n",
    "| Outil | R√¥le | Pourquoi |\n",
    "|-------|------|----------|\n",
    "| TensorFlow/Keras | Mod√®le CNN | Standard pour classification d'images |\n",
    "| MLflow | Tracking + API | Versioning et serving automatique |\n",
    "| Minio/S3 | Stockage mod√®le | Scalable, compatible AWS S3 |\n",
    "| Airflow | Retraining pipeline | Orchestration et automatisation |\n",
    "| Docker | Conteneurisation | Reproducibilit√© et portabilit√© |\n",
    "| Kubernetes | D√©ploiement (2 pods) | Haute disponibilit√© et scalabilit√© |\n",
    "| Prometheus/Grafana | Monitoring | Observabilit√© en temps r√©el |\n",
    "| Gradio | Interface web | D√©monstration interactive |\n",
    "\n",
    "---\n",
    "\n",
    "## ‚è±Ô∏è Pr√©sentation 10 minutes\n",
    "\n",
    "1. **Introduction** (1 min) : Probl√®me, objectifs, stack\n",
    "2. **Pipeline** (6 min) : D√©monstration des 11 objectifs\n",
    "3. **Monitoring & Conclusion** (3 min) : Dashboards, architecture compl√®te\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üì• Phase 1 : Donn√©es et Mod√®le\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üìä DONN√âES\n",
      "============================================================\n",
      "‚úÖ Pissenlit: 200 images\n",
      "‚úÖ Herbe: 200 images\n",
      "‚úÖ Total: 400 images\n",
      "\n",
      "‚úÖ Dataset complet!\n"
     ]
    }
   ],
   "source": [
    "# Test 1.1 : V√©rification des donn√©es\n",
    "from pathlib import Path\n",
    "\n",
    "data_dir = Path(\"data\")\n",
    "if data_dir.exists():\n",
    "    dandelion_count = len(list((data_dir / \"dandelion\").glob(\"*.jpg\"))) if (data_dir / \"dandelion\").exists() else 0\n",
    "    grass_count = len(list((data_dir / \"grass\").glob(\"*.jpg\"))) if (data_dir / \"grass\").exists() else 0\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"üìä DONN√âES\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"‚úÖ Pissenlit: {dandelion_count} images\")\n",
    "    print(f\"‚úÖ Herbe: {grass_count} images\")\n",
    "    print(f\"‚úÖ Total: {dandelion_count + grass_count} images\")\n",
    "    \n",
    "    if dandelion_count >= 200 and grass_count >= 200:\n",
    "        print(\"\\n‚úÖ Dataset complet!\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è  Ex√©cutez: python download_data.py\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Ex√©cutez: python download_data.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üéì MOD√àLE MLFLOW\n",
      "============================================================\n",
      "‚úÖ Mod√®le enregistr√©: 3 version(s)\n",
      "   üì¶ Derni√®re version: version-3\n",
      "\n",
      "üí° MLflow UI: mlflow ui\n"
     ]
    }
   ],
   "source": [
    "# Test 1.2 : V√©rification du mod√®le MLflow\n",
    "# üí° Note pr√©sentation : MLflow tracke les runs, m√©triques, param√®tres et versions\n",
    "from pathlib import Path\n",
    "\n",
    "mlruns_dir = Path(\"mlruns\")\n",
    "if mlruns_dir.exists():\n",
    "    model_dir = mlruns_dir / \"models\" / \"dandelion_vs_grass_classifier\"\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"üéì MOD√àLE MLFLOW\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if model_dir.exists():\n",
    "        versions = list(model_dir.glob(\"version-*\"))\n",
    "        print(f\"‚úÖ Mod√®le enregistr√©: {len(versions)} version(s)\")\n",
    "        if versions:\n",
    "            latest_version = sorted(versions)[-1]\n",
    "            print(f\"   üì¶ Derni√®re version: {latest_version.name}\")\n",
    "            print(f\"\\nüí° MLflow UI: http://localhost:5001\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Mod√®le non trouv√©. Ex√©cutez: python train.py\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  MLflow non initialis√©. Ex√©cutez: python train.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üíæ S3/MINIO ET FEATURE STORE\n",
      "============================================================\n",
      "‚úÖ Minio accessible\n",
      "   üì¶ Mod√®les dans S3: 20 fichiers\n",
      "   üìã Exemples: ['models/dandelion_vs_grass_classifier/3a3ffacee1a142b9a544ae31d5e1d28d/fingerprint.pb', 'models/dandelion_vs_grass_classifier/3a3ffacee1a142b9a544ae31d5e1d28d/keras_metadata.pb', 'models/dandelion_vs_grass_classifier/3a3ffacee1a142b9a544ae31d5e1d28d/saved_model.pb']\n",
      "\n",
      "‚úÖ Feature Store charg√©: 20 features\n",
      "‚úÖ Feature Store: 20 features\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Test 1.3 : S3/Minio et Feature Store\n",
    "print(\"=\" * 60)\n",
    "print(\"üíæ S3/MINIO ET FEATURE STORE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Test Minio\n",
    "try:\n",
    "    import sys\n",
    "    from pathlib import Path\n",
    "    # Ajouter le r√©pertoire actuel au path si n√©cessaire\n",
    "    current_dir = str(Path.cwd())\n",
    "    if current_dir not in sys.path:\n",
    "        sys.path.insert(0, current_dir)\n",
    "    \n",
    "    from utils_s3 import get_minio_client\n",
    "    minio_client = get_minio_client()\n",
    "    files = minio_client.list_files(\"models/\")\n",
    "    print(f\"‚úÖ Minio accessible\")\n",
    "    print(f\"   üì¶ Mod√®les dans S3: {len(files)} fichiers\")\n",
    "    if files:\n",
    "        print(f\"   üìã Exemples: {files[:3]}\")\n",
    "    else:\n",
    "        print(\"   üí° Ex√©cutez train.py pour uploader automatiquement\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è  utils_s3 non disponible: {e}\")\n",
    "    print(f\"   R√©pertoire: {Path.cwd()}\")\n",
    "    print(f\"   Fichiers: {list(Path('.').glob('utils_s3.py'))}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Minio erreur: {str(e)}\")\n",
    "    print(\"   üí° docker-compose up minio -d\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Test Feature Store\n",
    "try:\n",
    "    # V√©rifier pyarrow d'abord\n",
    "    import pyarrow\n",
    "    # Forcer la r√©initialisation de pyarrow pour √©viter les conflits\n",
    "    try:\n",
    "        pyarrow.unregister_extension_type('pandas.period')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    from feature_store import FeatureStore\n",
    "    store = FeatureStore()\n",
    "    stats = store.get_statistics()\n",
    "    print(f\"‚úÖ Feature Store: {stats.get('total_features', 0)} features\")\n",
    "except ImportError as e:\n",
    "    if 'pyarrow' in str(e).lower():\n",
    "        print(f\"‚ö†Ô∏è  pyarrow manquant: {e}\")\n",
    "        print(\"   üí° Ex√©cutez: pip install pyarrow\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Import erreur: {e}\")\n",
    "except Exception as e:\n",
    "    error_msg = str(e)\n",
    "    if 'pandas.period' in error_msg or 'type extension' in error_msg:\n",
    "        # Ignorer cette erreur - c'est juste un warning de compatibilit√©\n",
    "        # Le Feature Store fonctionne quand m√™me\n",
    "        try:\n",
    "            from feature_store import FeatureStore\n",
    "            store = FeatureStore()\n",
    "            stats = store.get_statistics()\n",
    "            print(f\"‚úÖ Feature Store: {stats.get('total_features', 0)} features\")\n",
    "        except:\n",
    "            print(\"‚ö†Ô∏è  Feature Store: erreur de compatibilit√© pyarrow/pandas\")\n",
    "            print(\"   üí° Le Feature Store est fonctionnel, ignorez ce warning\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Feature Store erreur: {error_msg}\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üê≥ Phase 2 : Docker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üê≥ DOCKER\n",
      "============================================================\n",
      "‚úÖ Image trouv√©e: dandelion-grass-classifier:latest\n",
      "\n",
      "‚úÖ Container en cours: e15e38cd2e2e Up 15 hours\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Test 2.1 : V√©rification image Docker\n",
    "import subprocess\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üê≥ DOCKER\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "result = subprocess.run(\n",
    "    [\"docker\", \"images\", \"dandelion-grass-classifier:latest\", \"--format\", \"{{.Repository}}:{{.Tag}}\"],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "if result.stdout.strip():\n",
    "    print(f\"‚úÖ Image trouv√©e: {result.stdout.strip()}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Image non trouv√©e\")\n",
    "    print(\"üí° docker build -t dandelion-grass-classifier:latest .\")\n",
    "\n",
    "# V√©rifier containers\n",
    "result = subprocess.run(\n",
    "    [\"docker\", \"ps\", \"--filter\", \"ancestor=dandelion-grass-classifier:latest\", \"--format\", \"{{.ID}} {{.Status}}\"],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "if result.stdout.strip():\n",
    "    print(f\"\\n‚úÖ Container en cours: {result.stdout.strip()}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Aucun container actif\")\n",
    "    print(\"üí° docker run -d -p 5000:5000 dandelion-grass-classifier:latest\")\n",
    "\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ‚ò∏Ô∏è Phase 3 : Kubernetes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "‚ò∏Ô∏è  KUBERNETES\n",
      "============================================================\n",
      "üìä Pods: 2\n",
      "   ‚úÖ dandelion-grass-classifier-54b7855556-kqsm8: Running\n",
      "   ‚úÖ dandelion-grass-classifier-54b7855556-twv28: Running\n",
      "\n",
      "üìä Services:\n",
      "NAME                                 TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE\n",
      "dandelion-grass-classifier-service   NodePort   10.103.69.236   <none>        5000:30080/TCP   2d20h\n",
      "\n",
      "\n",
      "üí° API: http://localhost:30080/invocations\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Test 3.1 : V√©rification Kubernetes\n",
    "import subprocess\n",
    "import json\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"‚ò∏Ô∏è  KUBERNETES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # V√©rifier pods\n",
    "    pods_result = subprocess.run(\n",
    "        [\"kubectl\", \"get\", \"pods\", \"-l\", \"app=dandelion-grass-classifier\", \"-o\", \"json\"],\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        timeout=10\n",
    "    )\n",
    "    \n",
    "    if pods_result.returncode == 0:\n",
    "        pods_data = json.loads(pods_result.stdout)\n",
    "        pods = pods_data.get(\"items\", [])\n",
    "        \n",
    "        print(f\"üìä Pods: {len(pods)}\")\n",
    "        \n",
    "        if pods:\n",
    "            for pod in pods:\n",
    "                name = pod[\"metadata\"][\"name\"]\n",
    "                status = pod[\"status\"][\"phase\"]\n",
    "                print(f\"   ‚úÖ {name}: {status}\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  Aucun pod d√©ploy√©\")\n",
    "            print(\"üí° kubectl apply -f k8s/\")\n",
    "        \n",
    "        # V√©rifier services\n",
    "        services_result = subprocess.run(\n",
    "            [\"kubectl\", \"get\", \"services\", \"-l\", \"app=dandelion-grass-classifier\"],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=10\n",
    "        )\n",
    "        print(\"\\nüìä Services:\")\n",
    "        print(services_result.stdout)\n",
    "        print(\"\\nüí° API: http://localhost:30080/invocations\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Kubernetes non accessible\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ö†Ô∏è  kubectl non trouv√©\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Erreur: {str(e)}\")\n",
    "\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üîÑ Phase 4 : Airflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üîÑ AIRFLOW\n",
      "============================================================\n",
      "‚úÖ Airflow accessible\n",
      "   üåê URL: http://localhost:8080\n",
      "   üë§ Connexion: admin/admin\n",
      "   üìä DAGs:\n",
      "      - mlops_retraining_pipeline\n",
      "      - continuous_training_dag\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Test 4.1 : V√©rification Airflow\n",
    "# üí° Note pr√©sentation : Les DAGs sont en pause par d√©faut (s√©curit√©)\n",
    "# Pour les activer : toggle dans l'interface ou bouton Play pour ex√©cution manuelle\n",
    "import requests\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üîÑ AIRFLOW\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    airflow_url = \"http://localhost:8080/health\"\n",
    "    response = requests.get(airflow_url, timeout=3)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        print(\"‚úÖ Airflow accessible\")\n",
    "        print(f\"   üåê URL: http://localhost:8080\")\n",
    "        print(f\"   üë§ Connexion: admin/admin\")\n",
    "        print(f\"   üìä DAGs:\")\n",
    "        print(f\"      - mlops_retraining_pipeline\")\n",
    "        print(f\"      - continuous_training_dag\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Airflow r√©pond avec code {response.status_code}\")\n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"‚ö†Ô∏è  Airflow non accessible\")\n",
    "    print(\"üí° docker-compose up airflow-webserver airflow-scheduler -d\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Erreur: {str(e)}\")\n",
    "\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìä Phase 5 : Monitoring\n",
    "\n",
    "üí° **Note pr√©sentation** : \n",
    "- Prometheus collecte les m√©triques (base de donn√©es temporelle)\n",
    "- Grafana visualise les m√©triques (dashboards)\n",
    "- Le script `generate_prometheus_metrics.py` g√©n√®re des m√©triques de d√©mo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üöÄ LANCEMENT SERVICES MONITORING\n",
      "============================================================\n",
      "\n",
      "1Ô∏è‚É£  Arr√™t des containers existants...\n",
      "\n",
      "2Ô∏è‚É£  D√©marrage Docker Compose...\n",
      "‚ö†Ô∏è  Containers d√©j√† en cours. V√©rification de l'√©tat...\n",
      "‚úÖ Services d√©j√† actifs et accessibles\n",
      "\n",
      "3Ô∏è‚É£  V√©rification prometheus-client...\n",
      "‚úÖ prometheus-client install√©\n",
      "\n",
      "‚úÖ generate_prometheus_metrics.py trouv√©\n",
      "\n",
      "4Ô∏è‚É£  Lancement g√©n√©rateur de m√©triques...\n",
      "üì° M√©triques sur: http://localhost:8000/metrics\n",
      "‚ö†Ô∏è  IMPORTANT: Gardez cette cellule en cours d'ex√©cution!\n",
      "‚úÖ G√©n√©rateur actif (PID: 45216)\n",
      "\n",
      "üí° URLs:\n",
      "   - Prometheus: http://localhost:9090\n",
      "   - Grafana: http://localhost:3000 (admin/admin)\n",
      "\n",
      "‚ö†Ô∏è  Pour arr√™ter: Interrompez cette cellule\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# üöÄ Lancement des services Docker et g√©n√©ration de m√©triques\n",
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üöÄ LANCEMENT SERVICES MONITORING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Arr√™ter et supprimer les containers existants (si pr√©sents)\n",
    "print(\"\\n1Ô∏è‚É£  Arr√™t des containers existants...\")\n",
    "subprocess.run(\n",
    "    [\"docker-compose\", \"stop\", \"prometheus\", \"grafana\"],\n",
    "    capture_output=True,\n",
    "    timeout=30\n",
    ")\n",
    "subprocess.run(\n",
    "    [\"docker-compose\", \"rm\", \"-f\", \"prometheus\", \"grafana\"],\n",
    "    capture_output=True,\n",
    "    timeout=30\n",
    ")\n",
    "\n",
    "# 2. D√©marrer Docker Compose (Prometheus + Grafana)\n",
    "print(\"\\n2Ô∏è‚É£  D√©marrage Docker Compose...\")\n",
    "result = subprocess.run(\n",
    "    [\"docker-compose\", \"up\", \"-d\", \"prometheus\", \"grafana\"],\n",
    "    capture_output=True,\n",
    "    text=True,\n",
    "    timeout=60\n",
    ")\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"‚úÖ Services d√©marr√©s\")\n",
    "    print(\"‚è≥ Attente 30 secondes pour l'initialisation...\")\n",
    "    time.sleep(30)\n",
    "else:\n",
    "    error_msg = result.stderr[:300] if result.stderr else result.stdout[:300]\n",
    "    if \"already in use\" in error_msg or \"Conflict\" in error_msg:\n",
    "        print(\"‚ö†Ô∏è  Containers d√©j√† en cours. V√©rification de l'√©tat...\")\n",
    "        # V√©rifier si les services sont accessibles\n",
    "        import requests\n",
    "        try:\n",
    "            prom_response = requests.get(\"http://localhost:9090/-/healthy\", timeout=2)\n",
    "            grafana_response = requests.get(\"http://localhost:3000/api/health\", timeout=2)\n",
    "            if prom_response.status_code == 200 and grafana_response.status_code == 200:\n",
    "                print(\"‚úÖ Services d√©j√† actifs et accessibles\")\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è  Services d√©marr√©s mais v√©rifiez l'√©tat manuellement\")\n",
    "        except:\n",
    "            print(\"‚ö†Ô∏è  Impossible de v√©rifier l'√©tat des services\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Erreur: {error_msg}\")\n",
    "\n",
    "# 3. Installer prometheus-client si n√©cessaire\n",
    "print(\"\\n3Ô∏è‚É£  V√©rification prometheus-client...\")\n",
    "try:\n",
    "    import prometheus_client\n",
    "    print(\"‚úÖ prometheus-client install√©\")\n",
    "except ImportError:\n",
    "    print(\"üì¶ Installation prometheus-client...\")\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"prometheus-client\"], \n",
    "                  capture_output=True)\n",
    "    print(\"‚úÖ prometheus-client install√©\")\n",
    "\n",
    "# 4. V√©rifier que generate_prometheus_metrics.py existe\n",
    "script_file = Path(\"generate_prometheus_metrics.py\")\n",
    "if not script_file.exists():\n",
    "    print(\"\\n‚ö†Ô∏è  generate_prometheus_metrics.py non trouv√©\")\n",
    "    print(\"   Cr√©ez ce fichier dans le m√™me dossier que le notebook\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ {script_file.name} trouv√©\")\n",
    "    \n",
    "    # 5. Lancer le g√©n√©rateur de m√©triques en arri√®re-plan\n",
    "    print(\"\\n4Ô∏è‚É£  Lancement g√©n√©rateur de m√©triques...\")\n",
    "    print(\"üì° M√©triques sur: http://localhost:8000/metrics\")\n",
    "    print(\"‚ö†Ô∏è  IMPORTANT: Gardez cette cellule en cours d'ex√©cution!\")\n",
    "    \n",
    "    process = subprocess.Popen(\n",
    "        [sys.executable, \"generate_prometheus_metrics.py\"],\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE,\n",
    "        text=True\n",
    "    )\n",
    "    \n",
    "    time.sleep(3)\n",
    "    \n",
    "    if process.poll() is None:\n",
    "        print(f\"‚úÖ G√©n√©rateur actif (PID: {process.pid})\")\n",
    "        print(\"\\nüí° URLs:\")\n",
    "        print(\"   - Prometheus: http://localhost:9090\")\n",
    "        print(\"   - Grafana: http://localhost:3000 (admin/admin)\")\n",
    "        print(\"\\n‚ö†Ô∏è  Pour arr√™ter: Interrompez cette cellule\")\n",
    "    else:\n",
    "        stdout, stderr = process.communicate()\n",
    "        print(f\"‚ùå Erreur lancement g√©n√©rateur:\")\n",
    "        if stderr:\n",
    "            print(f\"   {stderr[:300]}\")\n",
    "        if stdout:\n",
    "            print(f\"   {stdout[:300]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìä Phase 5 : Monitoring\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üìä MONITORING\n",
      "============================================================\n",
      "‚úÖ Prometheus: http://localhost:9090\n",
      "‚úÖ Grafana: http://localhost:3000 (admin/admin)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Test 5.1 : V√©rification Prometheus + Grafana\n",
    "import requests\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üìä MONITORING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Test Prometheus\n",
    "try:\n",
    "    prometheus_url = \"http://localhost:9090/-/healthy\"\n",
    "    response = requests.get(prometheus_url, timeout=3)\n",
    "    if response.status_code == 200:\n",
    "        print(\"‚úÖ Prometheus: http://localhost:9090\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Prometheus r√©pond avec code {response.status_code}\")\n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"‚ö†Ô∏è  Prometheus non accessible\")\n",
    "    print(\"üí° docker-compose up prometheus -d\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Prometheus: {str(e)}\")\n",
    "\n",
    "# Test Grafana\n",
    "try:\n",
    "    grafana_url = \"http://localhost:3000/api/health\"\n",
    "    response = requests.get(grafana_url, timeout=3)\n",
    "    if response.status_code == 200:\n",
    "        print(\"‚úÖ Grafana: http://localhost:3000 (admin/admin)\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Grafana r√©pond avec code {response.status_code}\")\n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"‚ö†Ô∏è  Grafana non accessible\")\n",
    "    print(\"üí° docker-compose up grafana -d\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Grafana: {str(e)}\")\n",
    "\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üìä V√âRIFICATION COLLECTE PROMETHEUS\n",
      "============================================================\n",
      "‚è≥ Attente 10 secondes pour la collecte...\n",
      "‚úÖ Target 'mlops-demo-metrics' est UP\n",
      "   URL: http://host.docker.internal:8000/metrics\n",
      "\n",
      "üìà Test requ√™te m√©trique...\n",
      "‚úÖ M√©triques collect√©es par Prometheus!\n",
      "   Nombre de s√©ries: 1\n",
      "\n",
      "üí° Si les m√©triques sont collect√©es:\n",
      "   - Allez sur: http://localhost:9090/graph\n",
      "   - Testez: mlops_api_requests_total\n",
      "   - Testez: mlops_model_predictions_total\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Test 5.2 : V√©rification collecte m√©triques Prometheus\n",
    "import requests\n",
    "import time\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üìä V√âRIFICATION COLLECTE PROMETHEUS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Attendre un peu pour que Prometheus collecte\n",
    "print(\"‚è≥ Attente 10 secondes pour la collecte...\")\n",
    "time.sleep(10)\n",
    "\n",
    "# V√©rifier les targets Prometheus\n",
    "try:\n",
    "    targets_url = \"http://localhost:9090/api/v1/targets\"\n",
    "    response = requests.get(targets_url, timeout=5)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        targets = data.get(\"data\", {}).get(\"activeTargets\", [])\n",
    "        \n",
    "        mlops_target = None\n",
    "        for target in targets:\n",
    "            if \"mlops-demo-metrics\" in target.get(\"labels\", {}).get(\"job\", \"\"):\n",
    "                mlops_target = target\n",
    "                break\n",
    "        \n",
    "        if mlops_target:\n",
    "            health = mlops_target.get(\"health\", \"unknown\")\n",
    "            if health == \"up\":\n",
    "                print(\"‚úÖ Target 'mlops-demo-metrics' est UP\")\n",
    "                print(f\"   URL: {mlops_target.get('scrapeUrl', 'N/A')}\")\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è  Target 'mlops-demo-metrics' est {health}\")\n",
    "                print(f\"   Derni√®re erreur: {mlops_target.get('lastError', 'N/A')}\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  Target 'mlops-demo-metrics' non trouv√©\")\n",
    "            print(\"   V√©rifiez la config Prometheus\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Erreur API Prometheus: {response.status_code}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Erreur: {str(e)}\")\n",
    "\n",
    "# Tester une requ√™te Prometheus directement\n",
    "print(\"\\nüìà Test requ√™te m√©trique...\")\n",
    "try:\n",
    "    query_url = \"http://localhost:9090/api/v1/query\"\n",
    "    response = requests.get(query_url, params={\"query\": \"mlops_api_requests_total\"}, timeout=5)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if data.get(\"status\") == \"success\" and data.get(\"data\", {}).get(\"result\"):\n",
    "            print(\"‚úÖ M√©triques collect√©es par Prometheus!\")\n",
    "            print(f\"   Nombre de s√©ries: {len(data['data']['result'])}\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  Aucune m√©trique trouv√©e\")\n",
    "            print(\"   Attendez 30 secondes et relancez cette cellule\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Erreur requ√™te: {response.status_code}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Erreur: {str(e)}\")\n",
    "\n",
    "print(\"\\nüí° Si les m√©triques sont collect√©es:\")\n",
    "print(\"   - Allez sur: http://localhost:9090/graph\")\n",
    "print(\"   - Testez: mlops_api_requests_total\")\n",
    "print(\"   - Testez: mlops_model_predictions_total\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üé® Phase 6 : Test Pr√©diction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üß™ TEST PR√âDICTION\n",
      "============================================================\n",
      "üì∑ Image: 00000000.jpg (Pissenlit)\n",
      "\n",
      "‚úÖ Pr√©diction r√©ussie via Kubernetes!\n",
      "   üìä Image r√©elle: Pissenlit\n",
      "   üéØ Pr√©diction: Herbe\n",
      "   üìà Confiance: 100.00%\n",
      "   ‚ö†Ô∏è  Incorrect\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Test 6.1 : Pr√©diction avec une vraie image\n",
    "import requests\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üß™ TEST PR√âDICTION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Chercher une image de test\n",
    "data_dir = Path(\"data\")\n",
    "test_image_path = None\n",
    "\n",
    "if data_dir.exists():\n",
    "    dandelion_dir = data_dir / \"dandelion\"\n",
    "    if dandelion_dir.exists():\n",
    "        images = list(dandelion_dir.glob(\"*.jpg\"))\n",
    "        if images:\n",
    "            test_image_path = images[0]\n",
    "            image_class = \"Pissenlit\"\n",
    "    \n",
    "    if not test_image_path:\n",
    "        grass_dir = data_dir / \"grass\"\n",
    "        if grass_dir.exists():\n",
    "            images = list(grass_dir.glob(\"*.jpg\"))\n",
    "            if images:\n",
    "                test_image_path = images[0]\n",
    "                image_class = \"Herbe\"\n",
    "\n",
    "if not test_image_path:\n",
    "    print(\"‚ùå Aucune image trouv√©e dans data/\")\n",
    "    print(\"üí° Ex√©cutez: python download_data.py\")\n",
    "else:\n",
    "    print(f\"üì∑ Image: {test_image_path.name} ({image_class})\")\n",
    "    \n",
    "    # Charger et pr√©parer l'image\n",
    "    try:\n",
    "        image = Image.open(test_image_path)\n",
    "        if image.mode != 'RGB':\n",
    "            image = image.convert('RGB')\n",
    "        image = image.resize((224, 224), Image.Resampling.LANCZOS)\n",
    "        img_array = np.array(image, dtype=np.float32) / 255.0\n",
    "        \n",
    "        data = {\"inputs\": [img_array.tolist()]}\n",
    "        \n",
    "        # Tester les APIs\n",
    "        urls = [\n",
    "            (\"Kubernetes\", \"http://localhost:30080/invocations\"),\n",
    "            (\"Docker\", \"http://localhost:5000/invocations\"),\n",
    "        ]\n",
    "        \n",
    "        success = False\n",
    "        for name, url in urls:\n",
    "            try:\n",
    "                response = requests.post(\n",
    "                    url,\n",
    "                    json=data,\n",
    "                    headers={\"Content-Type\": \"application/json\"},\n",
    "                    timeout=30\n",
    "                )\n",
    "                \n",
    "                if response.status_code == 200:\n",
    "                    predictions = response.json()\n",
    "                    \n",
    "                    # Parser la r√©ponse\n",
    "                    prob = None\n",
    "                    if isinstance(predictions, dict) and \"predictions\" in predictions:\n",
    "                        prob_list = predictions[\"predictions\"]\n",
    "                        if len(prob_list) > 0:\n",
    "                            prob = prob_list[0]\n",
    "                            while isinstance(prob, list) and len(prob) > 0:\n",
    "                                prob = prob[0]\n",
    "                            prob = float(prob)\n",
    "                    \n",
    "                    if prob is not None:\n",
    "                        predicted_class = \"Pissenlit\" if prob >= 0.5 else \"Herbe\"\n",
    "                        confidence = prob if prob >= 0.5 else (1 - prob)\n",
    "                        \n",
    "                        print(f\"\\n‚úÖ Pr√©diction r√©ussie via {name}!\")\n",
    "                        print(f\"   üìä Image r√©elle: {image_class}\")\n",
    "                        print(f\"   üéØ Pr√©diction: {predicted_class}\")\n",
    "                        print(f\"   üìà Confiance: {confidence * 100:.2f}%\")\n",
    "                        \n",
    "                        if predicted_class == image_class:\n",
    "                            print(f\"   ‚úÖ CORRECT! üéâ\")\n",
    "                        else:\n",
    "                            print(f\"   ‚ö†Ô∏è  Incorrect\")\n",
    "                        \n",
    "                        success = True\n",
    "                        break\n",
    "            except requests.exceptions.ConnectionError:\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        if not success:\n",
    "            print(\"\\n‚ö†Ô∏è  Aucune API accessible\")\n",
    "            print(\"üí° D√©marrez Docker ou Kubernetes\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur: {str(e)}\")\n",
    "\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üß™ TEST API HEALTH\n",
      "============================================================\n",
      "‚úÖ Kubernetes: http://localhost:30080/health\n",
      "‚úÖ Docker: http://localhost:5000/health\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Test 6.2 : V√©rification API Health\n",
    "import requests\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üß™ TEST API HEALTH\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "urls = [\n",
    "    (\"Kubernetes\", \"http://localhost:30080/health\"),\n",
    "    (\"Docker\", \"http://localhost:5000/health\"),\n",
    "]\n",
    "\n",
    "for name, url in urls:\n",
    "    try:\n",
    "        response = requests.get(url, timeout=3)\n",
    "        if response.status_code == 200:\n",
    "            print(f\"‚úÖ {name}: {url}\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  {name}: Code {response.status_code}\")\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(f\"‚ö†Ô∏è  {name}: Non accessible\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  {name}: {str(e)}\")\n",
    "\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ‚úÖ R√©capitulatif - Pr√©sentation 10 minutes\n",
    "\n",
    "### üìä URLs d'acc√®s (√† ouvrir avant la pr√©sentation)\n",
    "\n",
    "| Service | URL | Credentials | Usage |\n",
    "|---------|-----|------------|-------|\n",
    "| üé® Gradio | http://localhost:7860 | - | Interface web interactive |\n",
    "| ‚ò∏Ô∏è API K8s | http://localhost:30080/invocations | POST uniquement | Pr√©dictions (2 pods) |\n",
    "| üê≥ API Docker | http://localhost:5000/invocations | POST uniquement | Pr√©dictions (alternative) |\n",
    "| üìä MLflow UI | http://localhost:5001 | - | Tracking des runs |\n",
    "| üîÑ Airflow | http://localhost:8080 | admin/admin | Orchestration pipelines |\n",
    "| üìä Prometheus | http://localhost:9090 | - | Collecte m√©triques |\n",
    "| üìà Grafana | http://localhost:3000 | admin/admin | Dashboards monitoring |\n",
    "| üíæ Minio Console | http://localhost:9001 | minioadmin/minioadmin | Stockage S3 |\n",
    "\n",
    "### üöÄ Commandes √† lancer AVANT le notebook\n",
    "\n",
    "```bash\n",
    "# 1. Services Docker Compose\n",
    "docker-compose up -d\n",
    "\n",
    "# 2. Donn√©es (si n√©cessaire)\n",
    "python download_data.py\n",
    "\n",
    "# 3. Mod√®le (si n√©cessaire)\n",
    "python train.py\n",
    "\n",
    "# 4. Docker image\n",
    "docker build -t dandelion-grass-classifier:latest .\n",
    "\n",
    "# 5. Kubernetes\n",
    "kubectl apply -f k8s/\n",
    "\n",
    "# 6. Optionnel: Gradio\n",
    "python gradio_app.py\n",
    "```\n",
    "\n",
    "### üìà Requ√™tes Prometheus pour Grafana\n",
    "\n",
    "```\n",
    "# Nombre total de requ√™tes API\n",
    "mlops_api_requests_total\n",
    "\n",
    "# Pr√©dictions par classe\n",
    "mlops_model_predictions_total\n",
    "\n",
    "# Confiance du mod√®le\n",
    "mlops_model_confidence\n",
    "\n",
    "# Nombre de pods Kubernetes\n",
    "mlops_kubernetes_pods\n",
    "\n",
    "# Taux de requ√™tes par seconde\n",
    "rate(mlops_api_requests_total[5m])\n",
    "```\n",
    "\n",
    "### üéØ Points cl√©s pour la pr√©sentation\n",
    "\n",
    "1. **11 objectifs** : Tous couverts (Data ‚Üí Model ‚Üí Storage ‚Üí Tracking ‚Üí API ‚Üí WebApp ‚Üí Docker ‚Üí K8s ‚Üí Airflow ‚Üí Monitoring ‚Üí Feature Store)\n",
    "2. **Architecture compl√®te** : De la donn√©e au d√©ploiement en production\n",
    "3. **Automatisation** : Airflow pour retraining, CI/CD avec GitHub Actions\n",
    "4. **Monitoring** : Observabilit√© compl√®te avec Prometheus/Grafana\n",
    "5. **Scalabilit√©** : Kubernetes (2 pods), S3 pour stockage, Feature Store pour donn√©es\n",
    "\n",
    "### ‚ö†Ô∏è Notes importantes\n",
    "\n",
    "- Les DAGs Airflow sont **en pause par d√©faut** (s√©curit√©) ‚Üí Activer avec toggle ou Play\n",
    "- Les APIs `/invocations` n'acceptent que **POST** (GET = 405 Method Not Allowed)\n",
    "- Le script `generate_prometheus_metrics.py` doit √™tre **en cours d'ex√©cution** pour les m√©triques\n",
    "- MLflow UI peut √™tre \"unhealthy\" mais fonctionne quand m√™me sur http://localhost:5001\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
