"""
DAG Airflow pour Continuous Training (CT)
DÃ©clenchement automatique basÃ© sur diffÃ©rents triggers
"""
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.sensors.filesystem import FileSensor
from airflow.providers.amazon.aws.sensors.s3 import S3KeySensor
from datetime import datetime, timedelta
import os


default_args = {
    'owner': 'mlops_team',
    'depends_on_past': False,
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}


def check_model_performance():
    """VÃ©rifie les performances du modÃ¨le et dÃ©clenche retraining si nÃ©cessaire."""
    import mlflow
    import requests
    
    mlflow.set_tracking_uri("http://mlflow:5000")  # Si MLflow est dÃ©ployÃ©
    
    # RÃ©cupÃ©rer les derniÃ¨res mÃ©triques
    try:
        # Simuler une vÃ©rification de performance
        # En production, on rÃ©cupÃ©rerait les vraies mÃ©triques depuis MLflow
        api_url = "http://localhost:30080/health"
        response = requests.get(api_url, timeout=5)
        
        if response.status_code != 200:
            print("âš ï¸  ModÃ¨le en dÃ©gradation dÃ©tectÃ©e")
            return True  # DÃ©clencher retraining
        
        print("âœ… Performance du modÃ¨le OK")
        return False
        
    except Exception as e:
        print(f"âš ï¸  Erreur vÃ©rification performance: {str(e)}")
        return True  # En cas d'erreur, dÃ©clencher retraining


def trigger_retraining(**context):
    """DÃ©clenche le retraining si nÃ©cessaire."""
    should_retrain = check_model_performance()
    
    if should_retrain:
        print("ğŸš€ DÃ©clenchement du retraining...")
        # Importer et exÃ©cuter le pipeline de retraining
        from mlops_retraining_pipeline import (
            download_data_task,
            train_model_task,
            build_docker_task,
            deploy_k8s_task
        )
        
        download_data_task()
        train_model_task()
        build_docker_task()
        deploy_k8s_task()
        
        print("âœ… Retraining terminÃ©")
    else:
        print("â­ï¸  Retraining non nÃ©cessaire")


# DAG pour Continuous Training avec triggers
dag = DAG(
    'continuous_training',
    default_args=default_args,
    description='Continuous Training avec triggers automatiques',
    schedule_interval=timedelta(hours=6),  # VÃ©rification toutes les 6h
    start_date=datetime(2024, 1, 1),
    catchup=False,
    tags=['mlops', 'continuous_training', 'automated'],
)

# Sensor pour dÃ©tecter nouvelles donnÃ©es (exemple)
# new_data_sensor = FileSensor(
#     task_id='wait_for_new_data',
#     filepath='/opt/airflow/data/new_images',
#     fs_conn_id='fs_default',
#     poke_interval=300,  # VÃ©rifie toutes les 5 minutes
#     timeout=3600,  # Timeout aprÃ¨s 1h
#     dag=dag,
# )

# Sensor pour dÃ©tecter nouveau modÃ¨le dans S3
# s3_model_sensor = S3KeySensor(
#     task_id='wait_for_new_model',
#     bucket_name='mlops-models',
#     bucket_key='models/dandelion_vs_grass_classifier/',
#     aws_conn_id='aws_default',
#     poke_interval=60,
#     timeout=600,
#     dag=dag,
# )

# TÃ¢che de vÃ©rification de performance
check_performance = PythonOperator(
    task_id='check_model_performance',
    python_callable=check_model_performance,
    dag=dag,
)

# TÃ¢che de retraining conditionnel
trigger_retraining_task = PythonOperator(
    task_id='trigger_retraining',
    python_callable=trigger_retraining,
    dag=dag,
)

# DÃ©finir les dÃ©pendances
check_performance >> trigger_retraining_task

