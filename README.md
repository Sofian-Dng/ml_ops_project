# ğŸš€ Pipeline MLOps - Classification Binaire d'Images

**Classification pissenlit vs herbe avec pipeline MLOps **

## ğŸ“Š Stack Technique

- **ModÃ¨le**: TensorFlow/Keras (CNN)
- **Tracking & API**: MLflow
- **Storage S3**: Minio (S3 compatible)
- **Feature Store**: Parquet + MySQL
- **Orchestration**: Apache Airflow
- **Conteneurisation**: Docker
- **DÃ©ploiement**: Kubernetes (2 pods)
- **CI/CD**: GitHub Actions
- **Monitoring**: Prometheus + Grafana
- **Interface**: Gradio


## ğŸ“ Structure du Projet

```
mlops-project-git/
â”œâ”€â”€ NOTEBOOK_PRESENTATION_FINAL.ipynb  # Notebook prÃ©sentation
â”œâ”€â”€ download_data.py                   # TÃ©lÃ©chargement images
â”œâ”€â”€ train.py                           # EntraÃ®nement modÃ¨le
â”œâ”€â”€ gradio_app.py                      # Interface web
â”œâ”€â”€ utils_s3.py                        # Client Minio/S3
â”œâ”€â”€ feature_store.py                   # Feature Store
â”œâ”€â”€ requirements.txt                   # DÃ©pendances Python
â”œâ”€â”€ Dockerfile                         # Image Docker (local)
â”œâ”€â”€ Dockerfile.s3                      # Image Docker (depuis S3)
â”œâ”€â”€ entrypoint.sh                      # Script dÃ©marrage Docker
â”œâ”€â”€ entrypoint_s3.sh                   # Script dÃ©marrage Docker S3
â”œâ”€â”€ docker-compose.yml                 # Services (Minio, Airflow, Monitoring)
â”œâ”€â”€ init_db.sql                        # Initialisation MySQL
â”œâ”€â”€ k8s/
â”‚   â”œâ”€â”€ deployment.yaml                # Deployment Kubernetes
â”‚   â””â”€â”€ service.yaml                   # Service Kubernetes
â”œâ”€â”€ airflow/
â”‚   â””â”€â”€ dags/
â”‚       â”œâ”€â”€ mlops_retraining_pipeline.py
â”‚       â””â”€â”€ continuous_training_dag.py
â”œâ”€â”€ monitoring/
â”‚   â”œâ”€â”€ prometheus.yml
â”‚   â””â”€â”€ grafana/
â”‚       â”œâ”€â”€ datasources/prometheus.yml
â”‚       â””â”€â”€ dashboards/
â”‚           â”œâ”€â”€ dashboard.json
â”‚           â””â”€â”€ mlops_dashboard.json
â””â”€â”€ .github/
    â””â”€â”€ workflows/
        â””â”€â”€ mlops-pipeline.yml         # CI/CD GitHub Actions
```



### 1. DÃ©pendances Python

```bash
pip install -r requirements.txt
```

### 2. Services Docker Compose

```bash
# DÃ©marrer tous les services
docker-compose up -d

# Services disponibles:
# - Minio: http://localhost:9001 (minioadmin/minioadmin)
# - Airflow: http://localhost:8080 (admin/admin)
# - Prometheus: http://localhost:9090
# - Grafana: http://localhost:3000 (admin/admin)
# - MySQL: localhost:3306
```

## ğŸ“‹ Utilisation

### Phase 1 : DonnÃ©es et ModÃ¨le

```bash
# 1. TÃ©lÃ©charger les donnÃ©es (400 images)
python download_data.py

# 2. EntraÃ®ner le modÃ¨le (5-10 minutes)
python train.py
```

**RÃ©sultat** :
- ModÃ¨le enregistrÃ© dans `mlruns/` (MLflow)
- ModÃ¨le uploadÃ© vers Minio/S3
- Features extraites et stockÃ©es

### Phase 2 : Docker

```bash
# Build l'image Docker
docker build -t dandelion-grass-classifier:latest .

# Tester localement
docker run -p 5000:5000 dandelion-grass-classifier:latest
```

**API accessible** : http://localhost:5000/invocations

### Phase 3 : Kubernetes

```bash
# DÃ©ployer
kubectl apply -f k8s/deployment.yaml
kubectl apply -f k8s/service.yaml

# VÃ©rifier
kubectl get pods
kubectl get services
```

**API accessible** : http://localhost:30080/invocations

### Phase 4 : Airflow

1. Ouvrir http://localhost:8080 (admin/admin)
2. Activer le DAG `mlops_retraining_pipeline`
3. DÃ©clencher manuellement ou attendre le schedule

### Phase 5 : Interface Gradio

```bash
python gradio_app.py
```

**Interface accessible** : http://localhost:7860

## ğŸ“Š Notebook de PrÃ©sentation

Ouvrir `NOTEBOOK_PRESENTATION_FINAL.ipynb` pour :
- Vue d'ensemble du projet
- Tests exÃ©cutables pour chaque phase
- DÃ©monstration complÃ¨te

## ğŸ”— URLs d'AccÃ¨s

| Service | URL | Credentials |
|---------|-----|------------|
| Gradio | http://localhost:7860 | - |
| API K8s | http://localhost:30080/invocations | - |
| API Docker | http://localhost:5000/invocations | - |
| MLflow UI | `mlflow ui` â†’ http://localhost:5000 | - |
| Airflow | http://localhost:8080 | admin/admin |
| Prometheus | http://localhost:9090 | - |
| Grafana | http://localhost:3000 | admin/admin |
| Minio Console | http://localhost:9001 | minioadmin/minioadmin |

## ğŸ› ï¸ Commandes Essentielles

```bash
# DÃ©marrer tous les services
docker-compose up -d

# EntraÃ®ner le modÃ¨le (avec upload S3 et Feature Store)
python train.py

# Lancer l'interface Gradio
python gradio_app.py

# VÃ©rifier les pods Kubernetes
kubectl get pods -l app=dandelion-grass-classifier

# Voir les logs d'un pod
kubectl logs <pod-name>
```

##  Notes 

- **ModÃ¨le** : CNN simple (3 couches convolutionnelles) pour classification binaire
- **Format API** : JSON avec `{"inputs": [[image_normalisÃ©e_224x224x3]]}`
- **MLflow** : Tracking automatique des mÃ©triques et versioning du modÃ¨le
- **Docker** : Utilise `mlflow models serve` (pas besoin de FastAPI)
- **Kubernetes** : 2 pods pour haute disponibilitÃ©, NodePort 30080
- **CI/CD** : Workflow GitHub Actions dÃ©clenchÃ© sur push vers `main`


