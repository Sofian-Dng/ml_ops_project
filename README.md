# ğŸš€ Pipeline MLOps - Classification Binaire d'Images

**Classification pissenlit vs herbe avec pipeline MLOps **

## ğŸ‘¥ Ã‰quipe

**Membres du projet :**
- Sofian Duong
- Joseph Dejean
- Maxandre Michel
- Paul Montier
- Mathieu Chabirand

## ğŸ“Š Stack Technique

- **ModÃ¨le**: TensorFlow/Keras (CNN)
- **Tracking & API**: MLflow
- **Storage S3**: Minio (S3 compatible)
- **Feature Store**: Parquet + MySQL
- **Orchestration**: Apache Airflow
- **Conteneurisation**: Docker
- **DÃ©ploiement**: Kubernetes (2 pods)
- **CI/CD**: GitHub Actions
- **Monitoring**: Prometheus + Grafana
- **Interface**: Gradio


## ğŸ“ Structure du Projet

```
mlops-project-git/
â”œâ”€â”€ NOTEBOOK_PRESENTATION_FINAL.ipynb  # Notebook prÃ©sentation
â”œâ”€â”€ download_data.py                   # TÃ©lÃ©chargement images
â”œâ”€â”€ train.py                           # EntraÃ®nement modÃ¨le
â”œâ”€â”€ gradio_app.py                      # Interface web
â”œâ”€â”€ utils_s3.py                        # Client Minio/S3
â”œâ”€â”€ feature_store.py                   # Feature Store
â”œâ”€â”€ requirements.txt                   # DÃ©pendances Python
â”œâ”€â”€ Dockerfile                         # Image Docker (local)
â”œâ”€â”€ Dockerfile.s3                      # Image Docker (depuis S3)
â”œâ”€â”€ entrypoint.sh                      # Script dÃ©marrage Docker
â”œâ”€â”€ entrypoint_s3.sh                   # Script dÃ©marrage Docker S3
â”œâ”€â”€ docker-compose.yml                 # Services (Minio, Airflow, Monitoring)
â”œâ”€â”€ init_db.sql                        # Initialisation MySQL
â”œâ”€â”€ k8s/
â”‚   â”œâ”€â”€ deployment.yaml                # Deployment Kubernetes
â”‚   â””â”€â”€ service.yaml                   # Service Kubernetes
â”œâ”€â”€ airflow/
â”‚   â””â”€â”€ dags/
â”‚       â”œâ”€â”€ mlops_retraining_pipeline.py
â”‚       â””â”€â”€ continuous_training_dag.py
â”œâ”€â”€ monitoring/
â”‚   â”œâ”€â”€ prometheus.yml
â”‚   â””â”€â”€ grafana/
â”‚       â”œâ”€â”€ datasources/prometheus.yml
â”‚       â””â”€â”€ dashboards/
â”‚           â”œâ”€â”€ dashboard.json
â”‚           â””â”€â”€ mlops_dashboard.json
â””â”€â”€ .github/
    â””â”€â”€ workflows/
        â””â”€â”€ mlops-pipeline.yml         # CI/CD GitHub Actions
```



### 1. DÃ©pendances Python

```bash
pip install -r requirements.txt
```

### 2. Services Docker Compose

```bash
# DÃ©marrer tous les services
docker-compose up -d

# Services disponibles:
# - Minio: http://localhost:9001 (minioadmin/minioadmin)
# - Airflow: http://localhost:8080 (admin/admin)
# - Prometheus: http://localhost:9090
# - Grafana: http://localhost:3000 (admin/admin)
# - MySQL: localhost:3306
```

## ğŸ“‹ Utilisation

### Phase 1 : DonnÃ©es et ModÃ¨le

```bash
# 1. TÃ©lÃ©charger les donnÃ©es (400 images)
python download_data.py

# 2. EntraÃ®ner le modÃ¨le (5-10 minutes)
python train.py
```

**RÃ©sultat** :
- ModÃ¨le enregistrÃ© dans `mlruns/` (MLflow)
- ModÃ¨le uploadÃ© vers Minio/S3
- Features extraites et stockÃ©es

### Phase 2 : Docker

```bash
# Build l'image Docker
docker build -t dandelion-grass-classifier:latest .

# Tester localement
docker run -p 5000:5000 dandelion-grass-classifier:latest
```

**API accessible** : http://localhost:5000/invocations

### Phase 3 : Kubernetes

```bash
# DÃ©ployer
kubectl apply -f k8s/deployment.yaml
kubectl apply -f k8s/service.yaml

# VÃ©rifier
kubectl get pods
kubectl get services
```

**API accessible** : http://localhost:30080/invocations

### Phase 4 : Airflow

1. Ouvrir http://localhost:8080 (admin/admin)
2. Activer le DAG `mlops_retraining_pipeline`
3. DÃ©clencher manuellement ou attendre le schedule

### Phase 5 : Interface Gradio

```bash
python gradio_app.py
```

**Interface accessible** : http://localhost:7860

## ğŸ“Š Notebook de PrÃ©sentation

Ouvrir `NOTEBOOK_PRESENTATION_FINAL.ipynb` pour :
- Vue d'ensemble du projet
- Tests exÃ©cutables pour chaque phase
- DÃ©monstration complÃ¨te

## ğŸ”— URLs d'AccÃ¨s

| Service | URL | Credentials |
|---------|-----|------------|
| Gradio | http://localhost:7860 | - |
| API K8s | http://localhost:30080/invocations | - |
| API Docker | http://localhost:5000/invocations | - |
| MLflow UI | `mlflow ui` â†’ http://localhost:5000 | - |
| Airflow | http://localhost:8080 | admin/admin |
| Prometheus | http://localhost:9090 | - |
| Grafana | http://localhost:3000 | admin/admin |
| Minio Console | http://localhost:9001 | minioadmin/minioadmin |

## ğŸ› ï¸ Commandes Essentielles

```bash
# DÃ©marrer tous les services
docker-compose up -d

# EntraÃ®ner le modÃ¨le (avec upload S3 et Feature Store)
python train.py

# Lancer l'interface Gradio
python gradio_app.py

# VÃ©rifier les pods Kubernetes
kubectl get pods -l app=dandelion-grass-classifier

# Voir les logs d'un pod
kubectl logs <pod-name>
```

<<<<<<< HEAD
## ğŸ“ Choix Techniques et Justifications

### Pourquoi ces outils ?

#### **TensorFlow/Keras**
- **Choix** : Framework de deep learning standard et bien documentÃ©
- **Avantage** : IntÃ©gration native avec MLflow, support complet de SavedModel

#### **MLflow**
- **Choix** : Solution open-source pour le tracking et versioning de modÃ¨les
- **Avantage** : Tracking automatique des mÃ©triques, versioning, API REST intÃ©grÃ©e (`mlflow models serve`)

#### **Minio (S3 compatible)**
- **Choix** : Stockage objet compatible S3 pour stocker les modÃ¨les
- **Avantage** : Facile Ã  dÃ©ployer localement, compatible avec boto3, migration vers AWS S3 transparente

#### **Apache Airflow**
- **Choix** : Orchestrateur de workflows open-source standard
- **Avantage** : DAGs visuels, scheduling flexible, gestion d'erreurs robuste

#### **Docker**
- **Choix** : Conteneurisation standard pour isoler les dÃ©pendances
- **Avantage** : ReproducibilitÃ©, portabilitÃ©, isolation des dÃ©pendances

#### **Kubernetes**
- **Choix** : Orchestration de conteneurs pour haute disponibilitÃ©
- **Alternative** : Docker Swarm (mais K8s est le standard industriel)
- **Avantage** : ScalabilitÃ© automatique, 2 pods pour haute disponibilitÃ©, load balancing

#### **Prometheus + Grafana**
- **Choix** : Stack de monitoring standard dans l'industrie
- **Avantage** : MÃ©triques temps rÃ©el, dashboards personnalisables, alerting

#### **Gradio**
- **Choix** : Interface web interactive rapide Ã  dÃ©velopper
- **Avantage** : Interface prÃªte en quelques lignes, upload d'images facile

#### **Feature Store (Parquet + MySQL)**
- **Choix** : Stockage de features avec mÃ©tadonnÃ©es
- **Avantage** : Parquet pour performances, MySQL pour mÃ©tadonnÃ©es et requÃªtes

## ğŸ§ª Tests

Le projet inclut une suite de tests complÃ¨te :

### Structure des tests

- **Tests unitaires** (`tests/test_unit.py`) : 10 tests pour les fonctions individuelles
- **Tests d'intÃ©gration** (`tests/test_integration.py`) : 8 tests pour les interactions entre composants
- **Tests end-to-end** (`tests/test_e2e.py`) : 11 tests pour le flux complet du pipeline

### ExÃ©cution des tests

```bash
# Tous les tests
python run_tests.py

# Ou avec pytest directement
python -m pytest tests/ -v

# Par catÃ©gorie
python -m pytest tests/test_unit.py -v
python -m pytest tests/test_integration.py -v
python -m pytest tests/test_e2e.py -v
```

> ğŸ“– Voir `tests/README.md` pour plus de dÃ©tails

## ğŸ“Š RÃ©sultats Obtenus

### MÃ©triques du ModÃ¨le

- **Accuracy d'entraÃ®nement** : ~85-90% (selon les runs)
- **Accuracy de validation** : ~80-85%
- **Format** : Classification binaire (Pissenlit vs Herbe)
- **Taille du modÃ¨le** : ~10-15 MB (SavedModel)

### Performance du Pipeline

- **Temps d'entraÃ®nement** : 5-10 minutes (400 images, 10 epochs)
- **Temps de dÃ©ploiement Docker** : ~2 minutes (build + run)
- **Temps de dÃ©ploiement Kubernetes** : ~1 minute (2 pods)
- **Latence API** : < 500ms par prÃ©diction


## ğŸ³ Docker Hub

### Image Docker disponible

L'image Docker du modÃ¨le est disponible sur Docker Hub :

**URL de l'image :** https://hub.docker.com/r/khal160/dandelion-grass-classifier

âœ… Image publiÃ©e et accessible publiquement sur Docker Hub.

### Pull et utilisation

```bash
# Pull l'image depuis Docker Hub
docker pull khal160/dandelion-grass-classifier:latest

# Lancer le container
docker run -p 5000:5000 khal160/dandelion-grass-classifier:latest
```

### Push vers Docker Hub

```bash
# 1. Se connecter Ã  Docker Hub
docker login

# 2. Tag l'image
docker tag dandelion-grass-classifier:latest khal160/dandelion-grass-classifier:latest

# 3. Push l'image
docker push khal160/dandelion-grass-classifier:latest
```

## ğŸ“ Notes Techniques

- **ModÃ¨le** : CNN simple (3 couches convolutionnelles) pour classification binaire
- **Format API** : JSON avec `{"inputs": [[image_normalisÃ©e_224x224x3]]}`
- **MLflow** : Tracking automatique des mÃ©triques et versioning du modÃ¨le
- **Docker** : Utilise `mlflow models serve` (pas besoin de FastAPI)
- **Kubernetes** : 2 pods pour haute disponibilitÃ©, NodePort 30080
- **CI/CD** : Workflow GitHub Actions dÃ©clenchÃ© sur push vers `main`
- **Tests** : Suite complÃ¨te de tests unitaires, intÃ©gration et E2E

## ğŸ”„ CI/CD Pipeline

Le pipeline CI/CD GitHub Actions :

1. **Checkout** du code
2. **Installation** des dÃ©pendances Python
3. **TÃ©lÃ©chargement** des donnÃ©es d'entraÃ®nement
4. **EntraÃ®nement** du modÃ¨le avec MLflow
5. **Build** de l'image Docker
6. **DÃ©ploiement** (optionnel, selon configuration)

> ğŸ“– Voir `.github/workflows/mlops-pipeline.yml` pour les dÃ©tails


